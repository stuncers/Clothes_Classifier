{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted number for total Earn Products: 356\n",
      "Element not found or error occurred in i=9\n",
      "If you can't get body div; Check for /html/body/div[?] in source !\n",
      "Element found for i=:6\n",
      "html_body_div[6]\n",
      "If you can't get body div; Check for /html/body/div[?] in source !\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Wait for scrape...\n",
      "*\n",
      "*\n",
      "*\n",
      "Inner Exception: 'NoneType' object has no attribute 'click'\n",
      "Outer Exception Last: Pre-calculated number of asset scrape has finished!\n",
      "Execution time: 13.428160905838013 seconds\n",
      "Execution time: 0.22380268176396687 minutes\n",
      "All the data scraped! Enjoy your day!\n",
      "The data has been saved as \"2023-09-06-Binance-APRs.xlsx\"\n"
     ]
    }
   ],
   "source": [
    "#pip install selenium\n",
    "#pip install pandas\n",
    "#pip install openpyxl\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import re\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    " \n",
    "\n",
    " \n",
    "\n",
    "# Create a new instance of the Firefox driver\n",
    "from selenium import webdriver\n",
    "\n",
    " \n",
    "\n",
    "# Firefox tarayıcının yolunu belirtin\n",
    "#firefox_path = \"C:\\\\Users\\\\necati.keskin\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps\\\\firefox.exe\"\n",
    "\n",
    " \n",
    "\n",
    "# Firefox WebDriver'ı başlatın\n",
    "#driver = webdriver.Firefox(firefox_binary=firefox_path)\n",
    "\n",
    " \n",
    "\n",
    "# Navigate to the webpage\n",
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()))\n",
    "driver.get(\"https://www.binance.com/en/simple-earn\")\n",
    "\n",
    "\n",
    "\n",
    "# Wait for the page to load\n",
    "driver.implicitly_wait(10)\n",
    "#### Closing pop-ups\n",
    "time.sleep(3)\n",
    "target_element = driver.find_element(By.XPATH, '//*[@id=\"onetrust-reject-all-handler\"]')\n",
    "target_element.click()\n",
    "time.sleep(1)\n",
    "target_element = driver.find_element(By.XPATH, '/html/body/div[1]/div[2]/div[1]/div[2]/div[3]/button')\n",
    "target_element.click()\n",
    "######\n",
    "\n",
    "\n",
    "####\n",
    "time.sleep(2)\n",
    "target_element = driver.find_element(By.XPATH, '/html/body/div[1]/div[2]/div[4]/div[2]')\n",
    "text = target_element.text\n",
    "match = re.search(r'\\d+', text)\n",
    "if match:\n",
    "    different_type_of_earn_assets = int(match.group())\n",
    "    print(\"Extracted number for total Earn Products:\", different_type_of_earn_assets)\n",
    "else:\n",
    "    print(\"No number found in the string\")\n",
    "\n",
    "\n",
    "target_element.click()\n",
    "#########\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Checking for body_div number\n",
    "\n",
    "html_body_div_list=[9,6,11]\n",
    "for i in html_body_div_list:\n",
    "    try:\n",
    "        element=driver.find_element(By.XPATH, '/html/body/div['+str(i)+']/div[1]/div/div[2]/div/div/div[1]')\n",
    "        # If element is found, do something with it here\n",
    "        print(\"Element found for i=:\"+str(i))\n",
    "        print(f'html_body_div[{i}]')\n",
    "        html_body_div = i\n",
    "        break\n",
    "    except:\n",
    "        print(\"Element not found or error occurred in i=\"+str(i))\n",
    "    finally:\n",
    "        print(\"If you can't get body div; Check for /html/body/div[?] in source !\")\n",
    "#####\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "apr_list = []\n",
    "unique_assets = []\n",
    "for i in range(1, different_type_of_earn_assets+6):\n",
    "    try:\n",
    "        asset_xpath = f'/html/body/div[{html_body_div}]/div[1]/div/div[2]/div/div/div[{str(i)}]'\n",
    "        target_element = driver.find_element(By.XPATH, asset_xpath)\n",
    "        target_element.location_once_scrolled_into_view #new\n",
    "        text = target_element.text\n",
    "        lines = text.split('\\n')\n",
    "\n",
    "        # Find the index of 'Duration(Days)'\n",
    "        duration_index = -1\n",
    "\n",
    "        for i, line in enumerate(lines):\n",
    "            if line == 'Duration(Days)':\n",
    "                duration_index = i\n",
    "                break\n",
    "        first_item = lines[0]\n",
    "        if first_item in unique_assets:\n",
    "            pass\n",
    "        else:\n",
    "            unique_assets.append(first_item)\n",
    "            # Extract the duration values\n",
    "            duration_values = []\n",
    "            if duration_index != -1:\n",
    "                for i in range(duration_index + 1, len(lines)):\n",
    "                    if re.match(r'^\\d+$', lines[i]) or lines[i] == 'Flexible':\n",
    "                        duration_values.append(lines[i])    \n",
    "\n",
    "            try:\n",
    "\n",
    "                target_element = driver.find_element(By.XPATH, asset_xpath)\n",
    "                target_element.location_once_scrolled_into_view #new \n",
    "\n",
    "                # ... Your other code ...\n",
    "\n",
    "                for j in range(1, len(duration_values)+1):\n",
    "                    asset_future_xpath = asset_xpath + f'/div[2]/div[1]/div[2]/div[{j}]'\n",
    "                    try:\n",
    "                        asset = []\n",
    "                        target_element = driver.find_element(By.XPATH, asset_future_xpath)\n",
    "                        #target_element.location_once_scrolled_into_view\n",
    "                        target_element.click()\n",
    "                        asset.append(target_element.text)  # getting future text like flex or 30\n",
    "                        ## Extracting Text\n",
    "                        target_element = driver.find_element(By.XPATH, asset_xpath)\n",
    "                        lines = target_element.text.split('\\n')\n",
    "                        asset.append(lines[0].split('\\\\')[0])\n",
    "                        if '+' in lines:\n",
    "                            asset.append((lines[1].split('\\\\')[0])+(lines[2].split('\\\\')[0])+(lines[3].split('\\\\')[0]))\n",
    "                        else:\n",
    "                            asset.append(lines[1].split('\\\\')[0])\n",
    "                        asset.append(lines[-1].split('\\\\')[-1])\n",
    "                        #print(asset)\n",
    "                        apr_list.append(asset)\n",
    "                        #print(len(apr_list))\n",
    "                        print(\"Wait for scrape...\")\n",
    "                        print(\"*\")\n",
    "                        print(\"*\")\n",
    "                        print(\"*\")\n",
    "                    except Exception as e:\n",
    "                        print(\"Inner Exception:\", str(e))\n",
    "                        break\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\"Outer Exception:\", str(e))\n",
    "\n",
    "\n",
    "            \n",
    "    except Exception as e:\n",
    "        # should add another try then finally Close the browser #driver.quit()\n",
    "        print(\"Outer Exception Last:\", \"Pre-calculated number of asset scrape has finished!\")            \n",
    "        break\n",
    "\n",
    "# Calculate and print the execution time\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time} seconds\")\n",
    "as_min=execution_time/60\n",
    "print(f\"Execution time: {as_min} minutes\")\n",
    "\n",
    "try:\n",
    "    asset_xpath = f'/html/body/div[{html_body_div}]/div[1]/div/div[2]/div/div/div[{str(different_type_of_earn_assets+7)}]'\n",
    "    target_element = driver.find_element(By.XPATH, asset_xpath)\n",
    "    print('Check the source! Total earn asset number might be changed!')\n",
    "except:\n",
    "    print('All the data scraped! Enjoy your day!')\n",
    "driver.quit()\n",
    "\n",
    "# saving data\n",
    "columns = ['Days', 'Asset', 'APR', 'Condition']\n",
    "today = datetime.date.today()\n",
    "df = pd.DataFrame(apr_list, columns=columns)\n",
    "df.to_excel(f'{str(today)}-Binance-APRs.xlsx', index=False)\n",
    "print(f'The data has been saved as \"{str(today)}-Binance-APRs.xlsx\"')\n",
    "\n",
    "#\n",
    "##### Future notes:\n",
    "#while \n",
    "#    target_element = driver.find_element(By.XPATH, '/html/body/div[9]/div[1]/div/div[2]/div[2]')\n",
    " #   target_element.text\n",
    "  #  no element to be list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data has been saved as \"2023-09-06-Binance-APRs.xlsx\"\n"
     ]
    }
   ],
   "source": [
    "columns = ['Days', 'Asset', 'APR', 'Condition']\n",
    "today = datetime.date.today()\n",
    "df = pd.DataFrame(apr_list, columns=columns)\n",
    "save_path = f\"C:\\\\Users\\\\suat.tuncer\\\\OneDrive - ICRYPEX BILISIM A.S\\\\Desktop\\\\APRs\\\\{today}-Binance-APRs.xlsx\"\n",
    "df.to_excel(save_path, index=False)\n",
    "print(f'The data has been saved as \"{str(today)}-Binance-APRs.xlsx\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Days</th>\n",
       "      <th>Asset</th>\n",
       "      <th>APR</th>\n",
       "      <th>Condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Flexible</td>\n",
       "      <td>FDUSD</td>\n",
       "      <td>1.01%+6%</td>\n",
       "      <td>Subscribe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flexible</td>\n",
       "      <td>BLZ</td>\n",
       "      <td>28.61%</td>\n",
       "      <td>Subscribe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Flexible</td>\n",
       "      <td>CTK</td>\n",
       "      <td>15.57%</td>\n",
       "      <td>Subscribe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>CTK</td>\n",
       "      <td>11.9%</td>\n",
       "      <td>Subscribe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>CTK</td>\n",
       "      <td>12.9%</td>\n",
       "      <td>Subscribe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Days  Asset       APR  Condition\n",
       "0  Flexible  FDUSD  1.01%+6%  Subscribe\n",
       "1  Flexible    BLZ    28.61%  Subscribe\n",
       "2  Flexible    CTK    15.57%  Subscribe\n",
       "3        30    CTK     11.9%  Subscribe\n",
       "4        60    CTK     12.9%  Subscribe"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
